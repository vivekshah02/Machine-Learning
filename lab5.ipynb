{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8df0a19a-606b-4af0-82b0-501c3d1650cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f9cce7e-2b0b-4fd7-85c6-a3b5b359530d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Strength_N</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what scenario should I use mean and where s...</td>\n",
       "      <td>Mean is used to calculate the average.</td>\n",
       "      <td>-1</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is covariance and what is correlation?</td>\n",
       "      <td>Correlation measures the strength and directio...</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does a correlation of 0 versus a correlat...</td>\n",
       "      <td>The respondent did not provide an explanation ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can you name 1 classifier which is probabilist...</td>\n",
       "      <td>Naive Bayes is a probabilistic classifier.</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How would you go about designing a speech reco...</td>\n",
       "      <td>Collect a dataset, extract features, and selec...</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>What is the order of sequence in which this sh...</td>\n",
       "      <td>First, define the function using the def keywo...</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>Thank you, Sir.</td>\n",
       "      <td>-1</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Were you tense?</td>\n",
       "      <td>Sir.</td>\n",
       "      <td>-1</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Where do tensed?</td>\n",
       "      <td>No, Sir. Actually, the network issue and my ea...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Thank you very much and good night.</td>\n",
       "      <td>Sorry. Thank you. Thank you, Sir.</td>\n",
       "      <td>-1</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Question  \\\n",
       "0    In what scenario should I use mean and where s...   \n",
       "1          What is covariance and what is correlation?   \n",
       "2    What does a correlation of 0 versus a correlat...   \n",
       "3    Can you name 1 classifier which is probabilist...   \n",
       "4    How would you go about designing a speech reco...   \n",
       "..                                                 ...   \n",
       "239  What is the order of sequence in which this sh...   \n",
       "240                               Thank you very much.   \n",
       "241                                    Were you tense?   \n",
       "242                                   Where do tensed?   \n",
       "243                Thank you very much and good night.   \n",
       "\n",
       "                                                Answer  Strength_N Strength  \n",
       "0              Mean is used to calculate the average.           -1      Low  \n",
       "1    Correlation measures the strength and directio...           1     High  \n",
       "2    The respondent did not provide an explanation ...          -1      Low  \n",
       "3           Naive Bayes is a probabilistic classifier.           1     High  \n",
       "4    Collect a dataset, extract features, and selec...           0   Medium  \n",
       "..                                                 ...         ...      ...  \n",
       "239  First, define the function using the def keywo...           1     High  \n",
       "240                                    Thank you, Sir.          -1      Low  \n",
       "241                                               Sir.          -1      Low  \n",
       "242  No, Sir. Actually, the network issue and my ea...          -1      Low  \n",
       "243                  Sorry. Thank you. Thank you, Sir.          -1      Low  \n",
       "\n",
       "[244 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('./Audio_Team(11-26).xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f47994e-c1a4-40f9-ac41-2b5c86168820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -1\n",
       "1      1\n",
       "2     -1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "239    1\n",
       "240   -1\n",
       "241   -1\n",
       "242   -1\n",
       "243   -1\n",
       "Name: Strength_N, Length: 244, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_dataset = df['Strength_N']\n",
    "work_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42a90c8c-0c8b-44f1-904f-04ca27bb132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Strength_N'])  # Features (all columns except the target)\n",
    "y = df['Strength_N']  # Target (the column you're predicting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "350bac78-5e67-4461-a076-c824a20c62d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create the OneHotEncoder with the updated parameter\n",
    "encoder = OneHotEncoder(sparse_output=False)  # sparse_output=False to get a dense array\n",
    "\n",
    "# Apply the encoder to all columns (if all are categorical)\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Split the encoded data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5e27572-c969-4955-bd0f-3d99102aaea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train, y_train)   # Train the model with LogisticRegression for classification\n",
    "y_train_pred = reg.predict(X_train)   # Predict on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "200e8a1e-6e5b-4e79-85f1-0703d25ddd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.69309011e-15, -1.00000000e+00,  0.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -3.33066907e-16,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.38777878e-16, -5.96744876e-16, -1.00000000e+00, -8.46545056e-16,\n",
       "        2.22044605e-16, -1.00000000e+00, -1.02695630e-15, -1.00000000e+00,\n",
       "       -2.77555756e-16, -7.77156117e-16, -1.00000000e+00,  1.00000000e+00,\n",
       "       -1.00000000e+00, -5.27355937e-16, -1.05471187e-15, -1.00000000e+00,\n",
       "       -6.52256027e-16,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "       -1.00000000e+00, -4.57966998e-16,  1.00000000e+00, -4.02455846e-16,\n",
       "       -1.00000000e+00, -4.71844785e-16,  1.00000000e+00, -5.68989300e-16,\n",
       "       -5.68989300e-16, -1.00000000e+00, -5.27355937e-16, -4.02455846e-16,\n",
       "       -3.19189120e-16,  1.00000000e+00,  1.00000000e+00, -4.57966998e-16,\n",
       "        1.00000000e+00, -1.00000000e+00,  1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.38777878e-16, -1.00000000e+00, -4.99600361e-16,  1.00000000e+00,\n",
       "       -1.00000000e+00, -5.27355937e-16,  1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "       -4.44089210e-16, -4.44089210e-16, -1.00000000e+00,  1.00000000e+00,\n",
       "       -1.00000000e+00,  1.00000000e+00, -1.00000000e+00,  1.00000000e+00,\n",
       "       -1.00000000e+00, -4.44089210e-16, -5.13478149e-16, -4.16333634e-16,\n",
       "       -1.00000000e+00, -4.85722573e-16, -4.16333634e-16, -3.46944695e-16,\n",
       "       -1.00000000e+00, -1.00000000e+00, -4.16333634e-16,  1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  1.00000000e+00, -4.85722573e-16,\n",
       "       -1.00000000e+00,  1.00000000e+00, -5.13478149e-16,  1.00000000e+00,\n",
       "       -5.13478149e-16, -4.57966998e-16, -5.82867088e-16, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -5.96744876e-16,\n",
       "        1.00000000e+00, -4.57966998e-16, -4.02455846e-16,  1.00000000e+00,\n",
       "       -1.00000000e+00,  1.00000000e+00, -5.68989300e-16,  1.00000000e+00,\n",
       "        1.00000000e+00, -1.00000000e+00,  1.00000000e+00, -5.13478149e-16,\n",
       "       -5.82867088e-16, -5.41233725e-16, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00, -4.85722573e-16, -1.00000000e+00,\n",
       "        1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -4.99600361e-16, -1.00000000e+00,  1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -5.41233725e-16, -1.00000000e+00,  1.00000000e+00,\n",
       "       -3.46944695e-16, -1.00000000e+00, -5.41233725e-16,  1.00000000e+00,\n",
       "       -1.00000000e+00,  1.00000000e+00, -2.51187959e-15, -1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00, -1.00000000e+00, -4.85722573e-16,\n",
       "       -1.00000000e+00, -3.88578059e-16, -1.00000000e+00, -1.00000000e+00,\n",
       "       -5.13478149e-16, -1.00000000e+00, -1.00000000e+00,  1.00000000e+00,\n",
       "       -1.00000000e+00,  1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        1.00000000e+00, -3.88578059e-16, -3.74700271e-16, -1.00000000e+00,\n",
       "       -1.00000000e+00, -4.57966998e-16, -1.00000000e+00, -6.10622664e-16,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -4.85722573e-16,\n",
       "       -3.19189120e-16, -1.00000000e+00, -1.00000000e+00, -5.27355937e-16,\n",
       "       -4.71844785e-16, -4.57966998e-16,  1.00000000e+00, -4.02455846e-16,\n",
       "       -1.00000000e+00,  1.00000000e+00, -1.00000000e+00])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "368b7ed1-44d9-4995-9383-656f7dfcd9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate metrics for the training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "mape_train = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Perform prediction on the test data\n",
    "y_test_pred = reg.predict(X_test)\n",
    "\n",
    "# Calculate metrics for the test set\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "mape_test = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bcadc24-15f6-4fd6-8a01-f38054be3e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Metrics:\n",
      "MSE: 1.338780077321144e-30\n",
      "RMSE: 1.1570566439553181e-15\n",
      "MAPE: 0.7955128205128214\n",
      "RÂ² Score: 1.0\n",
      "\n",
      "Test Set Metrics:\n",
      "MSE: 0.013939646133394256\n",
      "RMSE: 0.1180662785616378\n",
      "MAPE: 31558126490252.246\n",
      "RÂ² Score: 0.9727450404183391\n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"Training Set Metrics:\")\n",
    "print(f\"MSE: {mse_train}\")\n",
    "print(f\"RMSE: {rmse_train}\")\n",
    "print(f\"MAPE: {mape_train}\")\n",
    "print(f\"RÂ² Score: {r2_train}\")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"MSE: {mse_test}\")\n",
    "print(f\"RMSE: {rmse_test}\")\n",
    "print(f\"MAPE: {mape_test}\")\n",
    "print(f\"RÂ² Score: {r2_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a784495f-aaa2-4b13-b48f-bbf79e44bd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels for each point in the training set:\n",
      "[1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1\n",
      " 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0\n",
      " 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0\n",
      " 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 1 0 1\n",
      " 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1\n",
      " 0 0 1 1 1 1 1 0 1 0]\n",
      "\n",
      "Cluster Centers:\n",
      "[[ 1.14942529e-02  0.00000000e+00  1.14942529e-02  6.07153217e-18\n",
      "   1.14942529e-02  1.14942529e-02  1.14942529e-02  0.00000000e+00\n",
      "   1.14942529e-02  6.07153217e-18  0.00000000e+00  0.00000000e+00\n",
      "   6.07153217e-18  6.07153217e-18  6.07153217e-18  1.14942529e-02\n",
      "   0.00000000e+00  6.07153217e-18  0.00000000e+00  6.07153217e-18\n",
      "   1.14942529e-02  6.07153217e-18  1.14942529e-02  6.07153217e-18\n",
      "   1.14942529e-02  1.14942529e-02  1.14942529e-02  0.00000000e+00\n",
      "   0.00000000e+00  6.07153217e-18  1.14942529e-02  6.07153217e-18\n",
      "   0.00000000e+00  6.07153217e-18  0.00000000e+00  6.07153217e-18\n",
      "   0.00000000e+00  0.00000000e+00  1.14942529e-02  6.07153217e-18\n",
      "   0.00000000e+00  6.07153217e-18  0.00000000e+00  1.14942529e-02\n",
      "   1.14942529e-02  6.07153217e-18  0.00000000e+00  6.07153217e-18\n",
      "   1.14942529e-02  1.14942529e-02  1.14942529e-02  6.07153217e-18\n",
      "   6.07153217e-18  0.00000000e+00  0.00000000e+00  1.14942529e-02\n",
      "   6.07153217e-18  6.07153217e-18  1.14942529e-02  6.07153217e-18\n",
      "   6.07153217e-18  0.00000000e+00  6.07153217e-18  6.07153217e-18\n",
      "   1.14942529e-02  1.14942529e-02  1.14942529e-02  1.14942529e-02\n",
      "   6.07153217e-18  0.00000000e+00  6.07153217e-18  6.07153217e-18\n",
      "   1.14942529e-02  6.07153217e-18  1.14942529e-02  6.07153217e-18\n",
      "   1.14942529e-02  1.14942529e-02  6.07153217e-18  1.14942529e-02\n",
      "   1.14942529e-02  1.14942529e-02  6.07153217e-18  6.07153217e-18\n",
      "   6.07153217e-18  0.00000000e+00  0.00000000e+00  1.14942529e-02\n",
      "   1.14942529e-02  1.14942529e-02  1.14942529e-02  6.07153217e-18\n",
      "   0.00000000e+00  1.14942529e-02  6.07153217e-18  6.07153217e-18\n",
      "   1.14942529e-02  1.14942529e-02  1.14942529e-02  1.14942529e-02\n",
      "   1.14942529e-02  6.07153217e-18  1.14942529e-02  1.14942529e-02\n",
      "   0.00000000e+00  1.14942529e-02  0.00000000e+00  1.14942529e-02\n",
      "   1.14942529e-02  0.00000000e+00  1.14942529e-02  1.14942529e-02\n",
      "   6.07153217e-18  0.00000000e+00  1.14942529e-02  1.14942529e-02\n",
      "   6.07153217e-18  6.07153217e-18  1.14942529e-02  1.14942529e-02\n",
      "   0.00000000e+00  1.14942529e-02  1.14942529e-02  1.14942529e-02\n",
      "   6.07153217e-18  1.14942529e-02  1.14942529e-02  1.14942529e-02\n",
      "   1.14942529e-02  1.14942529e-02  0.00000000e+00  6.07153217e-18\n",
      "   6.07153217e-18  6.07153217e-18  6.07153217e-18  6.07153217e-18\n",
      "   6.07153217e-18  6.07153217e-18  0.00000000e+00  6.07153217e-18\n",
      "   6.07153217e-18  0.00000000e+00  6.07153217e-18  1.14942529e-02\n",
      "   0.00000000e+00  1.14942529e-02  6.07153217e-18  1.14942529e-02\n",
      "   1.14942529e-02  0.00000000e+00  6.07153217e-18  6.07153217e-18\n",
      "   0.00000000e+00  6.07153217e-18  1.21430643e-17  6.07153217e-18\n",
      "   6.07153217e-18  0.00000000e+00  6.07153217e-18  6.07153217e-18\n",
      "   1.14942529e-02  0.00000000e+00  0.00000000e+00  6.07153217e-18\n",
      "   0.00000000e+00  6.07153217e-18  6.07153217e-18  1.14942529e-02\n",
      "   6.07153217e-18  6.07153217e-18  1.14942529e-02  6.07153217e-18\n",
      "   6.07153217e-18  1.14942529e-02  6.07153217e-18  6.07153217e-18\n",
      "   1.14942529e-02  6.07153217e-18  1.14942529e-02  1.14942529e-02\n",
      "   6.07153217e-18  0.00000000e+00  6.07153217e-18  6.07153217e-18\n",
      "   1.14942529e-02  6.07153217e-18  6.07153217e-18  0.00000000e+00\n",
      "   1.14942529e-02  1.14942529e-02  6.07153217e-18  6.07153217e-18\n",
      "   6.07153217e-18  6.07153217e-18  1.21430643e-17  6.07153217e-18\n",
      "   6.07153217e-18  6.07153217e-18  6.07153217e-18  6.07153217e-18\n",
      "   6.07153217e-18  1.14942529e-02  6.07153217e-18  6.07153217e-18\n",
      "   6.07153217e-18  6.07153217e-18  1.14942529e-02  6.07153217e-18\n",
      "   6.07153217e-18  6.07153217e-18  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  6.07153217e-18  1.14942529e-02  1.14942529e-02\n",
      "   6.07153217e-18  6.07153217e-18  6.07153217e-18  1.14942529e-02\n",
      "   6.07153217e-18  1.14942529e-02  0.00000000e+00  6.07153217e-18\n",
      "   0.00000000e+00  1.14942529e-02  1.14942529e-02  6.07153217e-18\n",
      "   6.07153217e-18  0.00000000e+00  6.07153217e-18  1.14942529e-02\n",
      "   1.14942529e-02  1.14942529e-02  6.07153217e-18  1.14942529e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  6.07153217e-18\n",
      "   0.00000000e+00  6.07153217e-18  1.14942529e-02  6.07153217e-18\n",
      "   6.07153217e-18  6.07153217e-18  0.00000000e+00  1.14942529e-02\n",
      "   0.00000000e+00  1.14942529e-02  6.07153217e-18  6.07153217e-18\n",
      "   1.14942529e-02  6.07153217e-18  0.00000000e+00  6.07153217e-18\n",
      "   1.14942529e-02  6.07153217e-18  1.14942529e-02  0.00000000e+00\n",
      "   6.07153217e-18  1.14942529e-02  1.14942529e-02  6.07153217e-18\n",
      "   6.07153217e-18  6.07153217e-18  6.07153217e-18  6.07153217e-18\n",
      "   6.07153217e-18  6.07153217e-18  6.07153217e-18  1.14942529e-02\n",
      "   6.07153217e-18  6.07153217e-18  0.00000000e+00  6.07153217e-18\n",
      "   6.07153217e-18  0.00000000e+00  6.07153217e-18  6.07153217e-18\n",
      "   1.14942529e-02  1.14942529e-02  0.00000000e+00  6.07153217e-18\n",
      "   1.14942529e-02  6.07153217e-18  1.14942529e-02  1.14942529e-02\n",
      "   6.07153217e-18  6.07153217e-18  0.00000000e+00  0.00000000e+00\n",
      "   6.07153217e-18  6.07153217e-18  6.07153217e-18  0.00000000e+00\n",
      "   6.07153217e-18  6.07153217e-18  0.00000000e+00  1.14942529e-02\n",
      "   1.14942529e-02  1.14942529e-02  6.07153217e-18  6.07153217e-18\n",
      "   6.07153217e-18  0.00000000e+00  6.07153217e-18  6.07153217e-18\n",
      "   6.07153217e-18  0.00000000e+00  6.07153217e-18  6.07153217e-18\n",
      "   6.07153217e-18  0.00000000e+00  6.07153217e-18  6.07153217e-18\n",
      "   6.07153217e-18  6.07153217e-18  0.00000000e+00  6.07153217e-18\n",
      "   1.14942529e-02  6.07153217e-18  6.07153217e-18  1.14942529e-02\n",
      "   6.07153217e-18  0.00000000e+00  6.07153217e-18  0.00000000e+00\n",
      "   6.07153217e-18  1.14942529e-02  6.07153217e-18  6.07153217e-18\n",
      "   1.14942529e-02  6.07153217e-18  6.07153217e-18  0.00000000e+00\n",
      "   6.07153217e-18  6.07153217e-18  2.29885057e-02  1.14942529e-02\n",
      "   6.07153217e-18  2.29885057e-02  1.14942529e-02  1.14942529e-02\n",
      "   1.14942529e-02  1.14942529e-02  1.14942529e-02  6.07153217e-18\n",
      "   0.00000000e+00  6.07153217e-18  1.14942529e-02  1.14942529e-02\n",
      "   6.07153217e-18  1.14942529e-02  4.59770115e-02  5.74712644e-02\n",
      "   6.07153217e-18  1.14942529e-02  0.00000000e+00  1.14942529e-02\n",
      "   1.14942529e-02  6.07153217e-18  1.14942529e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  6.07153217e-18  6.07153217e-18\n",
      "   0.00000000e+00  6.07153217e-18  1.14942529e-02  6.07153217e-18\n",
      "   6.07153217e-18  1.14942529e-02  1.14942529e-02  1.14942529e-02\n",
      "   1.14942529e-02  0.00000000e+00  1.14942529e-02  1.14942529e-02\n",
      "   6.07153217e-18  6.07153217e-18  1.14942529e-02  1.14942529e-02\n",
      "   0.00000000e+00  0.00000000e+00  6.07153217e-18  6.07153217e-18\n",
      "   0.00000000e+00  6.07153217e-18  6.07153217e-18  0.00000000e+00\n",
      "   1.14942529e-02  6.07153217e-18  6.07153217e-18  0.00000000e+00\n",
      "   1.14942529e-02  6.07153217e-18  1.14942529e-02  1.14942529e-02\n",
      "   1.14942529e-02  1.14942529e-02  6.07153217e-18  6.07153217e-18\n",
      "   6.07153217e-18  6.07153217e-18  0.00000000e+00  1.14942529e-02\n",
      "   2.29885057e-02  2.29885057e-02  0.00000000e+00  6.07153217e-18\n",
      "   1.14942529e-02  0.00000000e+00  6.07153217e-18  6.07153217e-18\n",
      "   0.00000000e+00  6.07153217e-18  1.14942529e-02  0.00000000e+00\n",
      "   6.07153217e-18  6.07153217e-18  6.07153217e-18  0.00000000e+00\n",
      "   1.14942529e-02  1.14942529e-02  0.00000000e+00  6.07153217e-18\n",
      "   6.07153217e-18  1.14942529e-02  1.14942529e-02  0.00000000e+00\n",
      "   6.07153217e-18  1.14942529e-02  6.07153217e-18  6.07153217e-18\n",
      "   6.07153217e-18  6.07153217e-18  6.07153217e-18  0.00000000e+00\n",
      "   1.14942529e-02  6.07153217e-18  1.14942529e-02  9.19540230e-02\n",
      "   1.14942529e-02  1.14942529e-02  6.07153217e-18  6.07153217e-18\n",
      "   0.00000000e+00  1.14942529e-02  6.07153217e-18  6.07153217e-18\n",
      "   0.00000000e+00  6.07153217e-18  6.07153217e-18  2.49800181e-16\n",
      "   1.00000000e+00  3.88578059e-16  6.93889390e-17  6.07153217e-18]\n",
      " [ 7.80625564e-18  0.00000000e+00  7.80625564e-18  9.25925926e-03\n",
      "   7.80625564e-18  7.80625564e-18  7.80625564e-18  0.00000000e+00\n",
      "   7.80625564e-18  9.25925926e-03  0.00000000e+00  0.00000000e+00\n",
      "   9.25925926e-03  9.25925926e-03  9.25925926e-03  7.80625564e-18\n",
      "   0.00000000e+00  9.25925926e-03  0.00000000e+00  9.25925926e-03\n",
      "   7.80625564e-18  9.25925926e-03  7.80625564e-18  9.25925926e-03\n",
      "   7.80625564e-18  7.80625564e-18  7.80625564e-18  0.00000000e+00\n",
      "   0.00000000e+00  9.25925926e-03  7.80625564e-18  9.25925926e-03\n",
      "   0.00000000e+00  9.25925926e-03  0.00000000e+00  9.25925926e-03\n",
      "   0.00000000e+00  0.00000000e+00  7.80625564e-18  9.25925926e-03\n",
      "   0.00000000e+00  9.25925926e-03  0.00000000e+00  7.80625564e-18\n",
      "   7.80625564e-18  9.25925926e-03  0.00000000e+00  9.25925926e-03\n",
      "   7.80625564e-18  7.80625564e-18  7.80625564e-18  9.25925926e-03\n",
      "   9.25925926e-03  0.00000000e+00  0.00000000e+00  7.80625564e-18\n",
      "   9.25925926e-03  9.25925926e-03  7.80625564e-18  9.25925926e-03\n",
      "   9.25925926e-03  0.00000000e+00  9.25925926e-03  9.25925926e-03\n",
      "   7.80625564e-18  7.80625564e-18  7.80625564e-18  7.80625564e-18\n",
      "   9.25925926e-03  0.00000000e+00  9.25925926e-03  9.25925926e-03\n",
      "   7.80625564e-18  9.25925926e-03  9.25925926e-03  9.25925926e-03\n",
      "   7.80625564e-18  7.80625564e-18  9.25925926e-03  7.80625564e-18\n",
      "   7.80625564e-18  7.80625564e-18  9.25925926e-03  9.25925926e-03\n",
      "   9.25925926e-03  0.00000000e+00  0.00000000e+00  7.80625564e-18\n",
      "   7.80625564e-18  7.80625564e-18  7.80625564e-18  9.25925926e-03\n",
      "   0.00000000e+00  7.80625564e-18  9.25925926e-03  9.25925926e-03\n",
      "   7.80625564e-18  7.80625564e-18  7.80625564e-18  7.80625564e-18\n",
      "   7.80625564e-18  9.25925926e-03  7.80625564e-18  7.80625564e-18\n",
      "   0.00000000e+00  7.80625564e-18  0.00000000e+00  7.80625564e-18\n",
      "   7.80625564e-18  0.00000000e+00  7.80625564e-18  7.80625564e-18\n",
      "   9.25925926e-03  0.00000000e+00  7.80625564e-18  7.80625564e-18\n",
      "   9.25925926e-03  9.25925926e-03  7.80625564e-18  7.80625564e-18\n",
      "   0.00000000e+00  7.80625564e-18  7.80625564e-18  7.80625564e-18\n",
      "   9.25925926e-03  7.80625564e-18  7.80625564e-18  7.80625564e-18\n",
      "   7.80625564e-18  7.80625564e-18  0.00000000e+00  9.25925926e-03\n",
      "   9.25925926e-03  9.25925926e-03  9.25925926e-03  9.25925926e-03\n",
      "   9.25925926e-03  9.25925926e-03  0.00000000e+00  9.25925926e-03\n",
      "   9.25925926e-03  0.00000000e+00  9.25925926e-03  7.80625564e-18\n",
      "   0.00000000e+00  7.80625564e-18  9.25925926e-03  7.80625564e-18\n",
      "   7.80625564e-18  0.00000000e+00  9.25925926e-03  9.25925926e-03\n",
      "   0.00000000e+00  9.25925926e-03  1.85185185e-02  9.25925926e-03\n",
      "   9.25925926e-03  0.00000000e+00  9.25925926e-03  9.25925926e-03\n",
      "   7.80625564e-18  0.00000000e+00  0.00000000e+00  9.25925926e-03\n",
      "   0.00000000e+00  9.25925926e-03  9.25925926e-03  7.80625564e-18\n",
      "   9.25925926e-03  9.25925926e-03  7.80625564e-18  9.25925926e-03\n",
      "   9.25925926e-03  7.80625564e-18  9.25925926e-03  9.25925926e-03\n",
      "   7.80625564e-18  9.25925926e-03  7.80625564e-18  7.80625564e-18\n",
      "   9.25925926e-03  0.00000000e+00  9.25925926e-03  9.25925926e-03\n",
      "   9.25925926e-03  9.25925926e-03  9.25925926e-03  0.00000000e+00\n",
      "   7.80625564e-18  7.80625564e-18  9.25925926e-03  9.25925926e-03\n",
      "   9.25925926e-03  9.25925926e-03  1.85185185e-02  9.25925926e-03\n",
      "   9.25925926e-03  9.25925926e-03  9.25925926e-03  9.25925926e-03\n",
      "   9.25925926e-03  7.80625564e-18  9.25925926e-03  9.25925926e-03\n",
      "   9.25925926e-03  9.25925926e-03  7.80625564e-18  9.25925926e-03\n",
      "   9.25925926e-03  9.25925926e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  9.25925926e-03  7.80625564e-18  7.80625564e-18\n",
      "   9.25925926e-03  9.25925926e-03  9.25925926e-03  7.80625564e-18\n",
      "   9.25925926e-03  7.80625564e-18  0.00000000e+00  9.25925926e-03\n",
      "   0.00000000e+00  7.80625564e-18  7.80625564e-18  9.25925926e-03\n",
      "   9.25925926e-03  0.00000000e+00  9.25925926e-03  7.80625564e-18\n",
      "   7.80625564e-18  7.80625564e-18  9.25925926e-03  7.80625564e-18\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  9.25925926e-03\n",
      "   0.00000000e+00  9.25925926e-03  7.80625564e-18  9.25925926e-03\n",
      "   9.25925926e-03  9.25925926e-03  0.00000000e+00  7.80625564e-18\n",
      "   0.00000000e+00  7.80625564e-18  9.25925926e-03  9.25925926e-03\n",
      "   7.80625564e-18  9.25925926e-03  0.00000000e+00  9.25925926e-03\n",
      "   7.80625564e-18  9.25925926e-03  7.80625564e-18  0.00000000e+00\n",
      "   9.25925926e-03  7.80625564e-18  7.80625564e-18  9.25925926e-03\n",
      "   9.25925926e-03  9.25925926e-03  9.25925926e-03  9.25925926e-03\n",
      "   9.25925926e-03  9.25925926e-03  9.25925926e-03  7.80625564e-18\n",
      "   9.25925926e-03  9.25925926e-03  0.00000000e+00  9.25925926e-03\n",
      "   9.25925926e-03  0.00000000e+00  9.25925926e-03  9.25925926e-03\n",
      "   7.80625564e-18  7.80625564e-18  0.00000000e+00  9.25925926e-03\n",
      "   7.80625564e-18  9.25925926e-03  7.80625564e-18  7.80625564e-18\n",
      "   9.25925926e-03  9.25925926e-03  0.00000000e+00  0.00000000e+00\n",
      "   9.25925926e-03  9.25925926e-03  9.25925926e-03  0.00000000e+00\n",
      "   9.25925926e-03  9.25925926e-03  0.00000000e+00  7.80625564e-18\n",
      "   7.80625564e-18  7.80625564e-18  9.25925926e-03  9.25925926e-03\n",
      "   9.25925926e-03  0.00000000e+00  9.25925926e-03  9.25925926e-03\n",
      "   9.25925926e-03  0.00000000e+00  9.25925926e-03  9.25925926e-03\n",
      "   9.25925926e-03  0.00000000e+00  9.25925926e-03  9.25925926e-03\n",
      "   9.25925926e-03  9.25925926e-03  0.00000000e+00  9.25925926e-03\n",
      "   7.80625564e-18  9.25925926e-03  9.25925926e-03  7.80625564e-18\n",
      "   9.25925926e-03  0.00000000e+00  9.25925926e-03  0.00000000e+00\n",
      "   9.25925926e-03  7.80625564e-18  9.25925926e-03  9.25925926e-03\n",
      "   7.80625564e-18  9.25925926e-03  9.25925926e-03  0.00000000e+00\n",
      "   9.25925926e-03  9.25925926e-03  1.56125113e-17  7.80625564e-18\n",
      "   9.25925926e-03  1.56125113e-17  7.80625564e-18  7.80625564e-18\n",
      "   7.80625564e-18  7.80625564e-18  7.80625564e-18  9.25925926e-03\n",
      "   0.00000000e+00  9.25925926e-03  7.80625564e-18  7.80625564e-18\n",
      "   9.25925926e-03  7.80625564e-18  3.12250226e-17  5.55111512e-17\n",
      "   9.25925926e-03  7.80625564e-18  0.00000000e+00  7.80625564e-18\n",
      "   7.80625564e-18  9.25925926e-03  7.80625564e-18  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  9.25925926e-03  9.25925926e-03\n",
      "   0.00000000e+00  9.25925926e-03  7.80625564e-18  9.25925926e-03\n",
      "   9.25925926e-03  7.80625564e-18  7.80625564e-18  7.80625564e-18\n",
      "   7.80625564e-18  0.00000000e+00  7.80625564e-18  7.80625564e-18\n",
      "   9.25925926e-03  9.25925926e-03  7.80625564e-18  7.80625564e-18\n",
      "   0.00000000e+00  0.00000000e+00  9.25925926e-03  9.25925926e-03\n",
      "   0.00000000e+00  9.25925926e-03  9.25925926e-03  0.00000000e+00\n",
      "   7.80625564e-18  9.25925926e-03  9.25925926e-03  0.00000000e+00\n",
      "   7.80625564e-18  9.25925926e-03  7.80625564e-18  7.80625564e-18\n",
      "   7.80625564e-18  7.80625564e-18  9.25925926e-03  9.25925926e-03\n",
      "   9.25925926e-03  9.25925926e-03  0.00000000e+00  7.80625564e-18\n",
      "   1.56125113e-17  1.56125113e-17  0.00000000e+00  9.25925926e-03\n",
      "   7.80625564e-18  0.00000000e+00  9.25925926e-03  9.25925926e-03\n",
      "   0.00000000e+00  9.25925926e-03  7.80625564e-18  0.00000000e+00\n",
      "   9.25925926e-03  9.25925926e-03  9.25925926e-03  0.00000000e+00\n",
      "   7.80625564e-18  7.80625564e-18  0.00000000e+00  9.25925926e-03\n",
      "   9.25925926e-03  7.80625564e-18  7.80625564e-18  0.00000000e+00\n",
      "   9.25925926e-03  7.80625564e-18  9.25925926e-03  9.25925926e-03\n",
      "   9.25925926e-03  9.25925926e-03  9.25925926e-03  0.00000000e+00\n",
      "   7.80625564e-18  9.25925926e-03  7.80625564e-18  2.77777778e-02\n",
      "   7.80625564e-18  7.80625564e-18  9.25925926e-03  9.25925926e-03\n",
      "   0.00000000e+00  7.80625564e-18  9.25925926e-03  9.25925926e-03\n",
      "   0.00000000e+00  9.25925926e-03  9.25925926e-03  3.33333333e-01\n",
      "  -1.66533454e-16  6.01851852e-01  5.55555556e-02  9.25925926e-03]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Step 1: Perform k-means clustering on the training data\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=\"auto\").fit(X_train)\n",
    "\n",
    "# Step 2: Retrieve the labels assigned to each data point\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Step 3: Retrieve the cluster centers\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "# Display the results\n",
    "print(\"Cluster Labels for each point in the training set:\")\n",
    "print(cluster_labels)\n",
    "\n",
    "print(\"\\nCluster Centers:\")\n",
    "print(cluster_centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a158905f-f09a-490a-9e43-8d8ffd5d1831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.1308378996270971\n",
      "Calinski-Harabasz Score: 32.155281908819546\n",
      "Davies-Bouldin Index: 2.412744044668015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "# Step 1: Perform k-means clustering on the training data\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=\"auto\").fit(X_train)\n",
    "\n",
    "# Step 2: Calculate clustering evaluation metrics\n",
    "\n",
    "# (i) Silhouette Score\n",
    "sil_score = silhouette_score(X_train, kmeans.labels_)\n",
    "print(\"Silhouette Score =\", sil_score)\n",
    "\n",
    "# (ii) Calinski-Harabasz Score\n",
    "ch_score = calinski_harabasz_score(X_train, kmeans.labels_)\n",
    "print(\"Calinski-Harabasz Score:\", ch_score)\n",
    "\n",
    "# (iii) Davies-Bouldin Index\n",
    "db_index = davies_bouldin_score(X_train, kmeans.labels_)\n",
    "print(\"Davies-Bouldin Index:\", db_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814cd6c8-a80f-483d-8a58-7c33c0496963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
