{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8df0a19a-606b-4af0-82b0-501c3d1650cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f9cce7e-2b0b-4fd7-85c6-a3b5b359530d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Strength</th>\n",
       "      <th>Strength_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So you someone tell me? Suppose we have to do ...</td>\n",
       "      <td>By speech recognition.</td>\n",
       "      <td>low</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK, tell me more.</td>\n",
       "      <td>And which it also text recognition.</td>\n",
       "      <td>low</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So can you help me understand how easily your ...</td>\n",
       "      <td>We can, like we can convert that speech into t...</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OK, so once you have, so you are saying that y...</td>\n",
       "      <td>Yes, Sir.</td>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK, so once the sentiment is available, sorry,...</td>\n",
       "      <td>I will preprocess the text and remove the noise.</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is noise in text?</td>\n",
       "      <td>I said I was saying, like in speech, and remov...</td>\n",
       "      <td>low</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yeah, but be a little more specific. You said ...</td>\n",
       "      <td>Punctuations, lower casing, etc., we can remov...</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OK, very good. You used a nice term called sto...</td>\n",
       "      <td>Things like in a sentence that do not carry si...</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Can you give an example?</td>\n",
       "      <td>Example, I have no idea I felt.</td>\n",
       "      <td>low</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OK. So you will remove stopwords from the sent...</td>\n",
       "      <td>Yes, Sir.</td>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Then what will you do?</td>\n",
       "      <td>After that, we will apply sentiment analysis t...</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How will you do sentiment analysis?</td>\n",
       "      <td>There are some different machine learning appr...</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Which approaches will you use? Can you name so...</td>\n",
       "      <td>Naive Bayes, RNN, SVM, etc.</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>So you have a text sentence, and you have remo...</td>\n",
       "      <td>I think you know.</td>\n",
       "      <td>low</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>So how would you use SVM for this scenario?</td>\n",
       "      <td>No, it's...</td>\n",
       "      <td>low</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>No problem. So tell me when you are doing a co...</td>\n",
       "      <td>While doing convolutional neural networks afte...</td>\n",
       "      <td>low</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>You do a training of CNNs, right?</td>\n",
       "      <td>Yes, Sir.</td>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What do you train for? What gets trained in th...</td>\n",
       "      <td>Pardon me. Text we can extract the text from...</td>\n",
       "      <td>low</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>So please tell me what is the difference betwe...</td>\n",
       "      <td>The difference between convolutional neural ne...</td>\n",
       "      <td>low</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>And convolutional neural networks?</td>\n",
       "      <td>We typically take the input data from the vector.</td>\n",
       "      <td>low</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Which ones, CNNs or general networks?</td>\n",
       "      <td>General neural networks, Sir. CNNs are used fo...</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CNN is used for image?</td>\n",
       "      <td>Yes, for image data. To improve accuracy, you ...</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Question  \\\n",
       "0   So you someone tell me? Suppose we have to do ...   \n",
       "1                                   OK, tell me more.   \n",
       "2   So can you help me understand how easily your ...   \n",
       "3   OK, so once you have, so you are saying that y...   \n",
       "4   OK, so once the sentiment is available, sorry,...   \n",
       "5                              What is noise in text?   \n",
       "6   Yeah, but be a little more specific. You said ...   \n",
       "7   OK, very good. You used a nice term called sto...   \n",
       "8                            Can you give an example?   \n",
       "9   OK. So you will remove stopwords from the sent...   \n",
       "10                             Then what will you do?   \n",
       "11                How will you do sentiment analysis?   \n",
       "12  Which approaches will you use? Can you name so...   \n",
       "13  So you have a text sentence, and you have remo...   \n",
       "14        So how would you use SVM for this scenario?   \n",
       "15  No problem. So tell me when you are doing a co...   \n",
       "16                  You do a training of CNNs, right?   \n",
       "17  What do you train for? What gets trained in th...   \n",
       "18  So please tell me what is the difference betwe...   \n",
       "19                 And convolutional neural networks?   \n",
       "20              Which ones, CNNs or general networks?   \n",
       "21                             CNN is used for image?   \n",
       "\n",
       "                                               Answer Strength  Strength_N  \n",
       "0                              By speech recognition.      low          -1  \n",
       "1                 And which it also text recognition.      low          -1  \n",
       "2   We can, like we can convert that speech into t...   medium           0  \n",
       "3                                           Yes, Sir.     high           1  \n",
       "4    I will preprocess the text and remove the noise.   medium           0  \n",
       "5   I said I was saying, like in speech, and remov...      low          -1  \n",
       "6   Punctuations, lower casing, etc., we can remov...   medium           0  \n",
       "7   Things like in a sentence that do not carry si...   medium           0  \n",
       "8                     Example, I have no idea I felt.      low          -1  \n",
       "9                                           Yes, Sir.     high           1  \n",
       "10  After that, we will apply sentiment analysis t...   medium           0  \n",
       "11  There are some different machine learning appr...   medium           0  \n",
       "12                        Naive Bayes, RNN, SVM, etc.   medium           0  \n",
       "13                                  I think you know.      low          -1  \n",
       "14                                        No, it's...      low          -1  \n",
       "15  While doing convolutional neural networks afte...      low          -1  \n",
       "16                                          Yes, Sir.     high           1  \n",
       "17    Pardon me. Text we can extract the text from...      low          -1  \n",
       "18  The difference between convolutional neural ne...      low          -1  \n",
       "19  We typically take the input data from the vector.      low          -1  \n",
       "20  General neural networks, Sir. CNNs are used fo...   medium           0  \n",
       "21  Yes, for image data. To improve accuracy, you ...   medium           0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r'D:\\text_dataset.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f47994e-c1a4-40f9-ac41-2b5c86168820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -1\n",
       "1    -1\n",
       "2     0\n",
       "3     1\n",
       "4     0\n",
       "5    -1\n",
       "6     0\n",
       "7     0\n",
       "8    -1\n",
       "9     1\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13   -1\n",
       "14   -1\n",
       "15   -1\n",
       "16    1\n",
       "17   -1\n",
       "18   -1\n",
       "19   -1\n",
       "20    0\n",
       "21    0\n",
       "Name: Strength_N, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_dataset = df['Strength_N']\n",
    "work_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42a90c8c-0c8b-44f1-904f-04ca27bb132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Strength_N'])  # Features (all columns except the target)\n",
    "y = df['Strength_N']  # Target (the column you're predicting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "350bac78-5e67-4461-a076-c824a20c62d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create the OneHotEncoder with the updated parameter\n",
    "encoder = OneHotEncoder(sparse_output=False)  # sparse_output=False to get a dense array\n",
    "\n",
    "# Apply the encoder to all columns (if all are categorical)\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Split the encoded data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5e27572-c969-4955-bd0f-3d99102aaea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train, y_train)   # Train the model with LogisticRegression for classification\n",
    "y_train_pred = reg.predict(X_train)   # Predict on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "200e8a1e-6e5b-4e79-85f1-0703d25ddd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.00000000e+00, -2.77555756e-16,  5.55111512e-17,  1.00000000e+00,\n",
       "       -3.05311332e-16, -1.00000000e+00, -1.94289029e-16, -1.00000000e+00,\n",
       "        1.00000000e+00, -2.22044605e-16,  1.00000000e+00, -2.77555756e-17,\n",
       "       -2.22044605e-16, -2.49800181e-16, -1.00000000e+00, -1.00000000e+00,\n",
       "       -8.32667268e-17])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "368b7ed1-44d9-4995-9383-656f7dfcd9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Calculate metrics for the training set\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "mape_train = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Perform prediction on the test data\n",
    "y_test_pred = reg.predict(X_test)\n",
    "\n",
    "# Calculate metrics for the test set\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "mape_test = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bcadc24-15f6-4fd6-8a01-f38054be3e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Metrics:\n",
      "MSE: 8.107032165902976e-32\n",
      "RMSE: 2.847285051747186e-16\n",
      "MAPE: 0.43382352941176483\n",
      "R² Score: 1.0\n",
      "\n",
      "Test Set Metrics:\n",
      "MSE: 0.05957848250479532\n",
      "RMSE: 0.24408703878902566\n",
      "MAPE: 0.24408703878902566\n",
      "R² Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"Training Set Metrics:\")\n",
    "print(f\"MSE: {mse_train}\")\n",
    "print(f\"RMSE: {rmse_train}\")\n",
    "print(f\"MAPE: {mape_train}\")\n",
    "print(f\"R² Score: {r2_train}\")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"MSE: {mse_test}\")\n",
    "print(f\"RMSE: {rmse_test}\")\n",
    "print(f\"MAPE: {mape_test}\")\n",
    "print(f\"R² Score: {r2_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a784495f-aaa2-4b13-b48f-bbf79e44bd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels for each point in the training set:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\n",
      "Cluster Centers:\n",
      "[[ 6.2500000e-02  6.2500000e-02  0.0000000e+00  6.2500000e-02\n",
      "   0.0000000e+00  6.2500000e-02  6.2500000e-02  0.0000000e+00\n",
      "   6.2500000e-02  6.2500000e-02  6.2500000e-02  6.2500000e-02\n",
      "   6.2500000e-02  0.0000000e+00  0.0000000e+00  6.2500000e-02\n",
      "   6.2500000e-02  6.2500000e-02  6.2500000e-02  6.2500000e-02\n",
      "  -6.9388939e-18  6.2500000e-02  6.2500000e-02  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  6.2500000e-02  6.2500000e-02\n",
      "   0.0000000e+00  6.2500000e-02  6.2500000e-02  6.2500000e-02\n",
      "   6.2500000e-02 -6.9388939e-18  6.2500000e-02  6.2500000e-02\n",
      "   6.2500000e-02  6.2500000e-02  6.2500000e-02  0.0000000e+00\n",
      "   1.8750000e-01  6.2500000e-02  1.8750000e-01  3.1250000e-01\n",
      "   5.0000000e-01]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  1.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   1.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Step 1: Perform k-means clustering on the training data\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=\"auto\").fit(X_train)\n",
    "\n",
    "# Step 2: Retrieve the labels assigned to each data point\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Step 3: Retrieve the cluster centers\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "# Display the results\n",
    "print(\"Cluster Labels for each point in the training set:\")\n",
    "print(cluster_labels)\n",
    "\n",
    "print(\"\\nCluster Centers:\")\n",
    "print(cluster_centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a158905f-f09a-490a-9e43-8d8ffd5d1831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814cd6c8-a80f-483d-8a58-7c33c0496963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
